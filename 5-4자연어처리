# ============================================================
# ë°ì´í„°ë§ˆì´ë‹(2) 5-4 ìì—°ì–´ì²˜ë¦¬(NLP)
# ============================================================

import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.feature_extraction.text import CountVectorizer

# ============================================================
# [1ë²ˆ ë¬¸ì œ] K-POP ê·¸ë£¹ ë²¡í„°í™” ë° ìœ ì‚¬ë„ ë¶„ì„
# ============================================================

print("="*60)
print("1ë²ˆ ë¬¸ì œ: K-POP ê·¸ë£¹ ë²¡í„°í™” ë° ìœ ì‚¬ë„ ë¶„ì„")
print("="*60)

# 1ï¸âƒ£ K-POP ê·¸ë£¹ [ë…¸ë˜, ì¶¤] ì ìˆ˜ ë²¡í„°
kpop_groups = {
    "NewJeans": [9, 8],
    "IVE": [8, 7],
    "LE_SSERAFIM": [7, 9],
    "SEVENTEEN": [8, 9],
    "NCT": [7, 8]
}

print("\nK-POP ê·¸ë£¹ ë²¡í„°:")
for group, vector in kpop_groups.items():
    print(f"{group}: {vector}")

# 2ï¸âƒ£ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
group_names = list(kpop_groups.keys())
group_vectors = np.array(list(kpop_groups.values()))

similarity_matrix = cosine_similarity(group_vectors)

max_sim = -1
best_pair = None

print("\nê·¸ë£¹ ê°„ ì½”ì‚¬ì¸ ìœ ì‚¬ë„:")
for i in range(len(group_names)):
    for j in range(i + 1, len(group_names)):
        sim = similarity_matrix[i][j]
        print(f"{group_names[i]} â†” {group_names[j]} : {sim:.3f}")
        if sim > max_sim:
            max_sim = sim
            best_pair = (group_names[i], group_names[j])

print("\nê°€ì¥ ë¹„ìŠ·í•œ ë‘ ê·¸ë£¹:")
print(best_pair, "ìœ ì‚¬ë„:", round(max_sim, 3))

# 3ï¸âƒ£ ì‹œê°í™”
plt.figure(figsize=(6, 6))
for name, vec in kpop_groups.items():
    x, y = vec
    plt.scatter(x, y, s=150)
    plt.text(x + 0.05, y + 0.05, name)

plt.xlabel("ë…¸ë˜ ì ìˆ˜")
plt.ylabel("ì¶¤ ì ìˆ˜")
plt.title("K-POP ê·¸ë£¹ ë²¡í„° ì‹œê°í™”")
plt.grid(True)
plt.xlim(0, 10)
plt.ylim(0, 10)
plt.show()


# ============================================================
# [2ë²ˆ ë¬¸ì œ] í•™ìƒ ë¦¬ë·° ë²¡í„°í™” ë° ì„±í–¥ ìœ ì‚¬ë„ ë¶„ì„
# ============================================================

import numpy as np
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.cluster import KMeans

# -----------------------------
# âœ… ì£¼ì œë³„ ë¦¬ë·° ë°ì´í„°
# -----------------------------
topic_reviews = {
    "í•œë¼ëŒ€í•™êµ_í•™ìƒì‹ë‹¹": {
        "Student1": "ê°€ê²©ì´ ì‹¸ê³  ì–‘ì´ ë§ì•„ì„œ ë§Œì¡±í•œë‹¤",
        "Student2": "ê°€ì„±ë¹„ê°€ ì¢‹ê³  ë©”ë‰´ê°€ ë‹¤ì–‘í•˜ë‹¤",
        "Student3": "ìœ„ìƒì´ ì•„ì‰½ê³  ì¤„ì´ ê¸¸ë‹¤",
        "Student4": "ë§›ìˆì§€ë§Œ ëŒ€ê¸°ì‹œê°„ì´ ê¸¸ë‹¤",
        "Student5": "ë°˜ì°¬ì´ ê¹”ë”í•˜ê³  ë§›ì´ ì¢‹ë‹¤"
    },
    "24ì‹œ_í¸ì˜ì ": {
        "Student1": "ì•¼ê°„ì—ë„ í¸ë¦¬í•˜ê³  ì ‘ê·¼ì„±ì´ ì¢‹ë‹¤",
        "Student2": "ì‹ ìƒí’ˆì´ ë§ê³  í–‰ì‚¬ë„ ë§ë‹¤",
        "Student3": "ê°€ê²©ì´ ë¹„ì‹¸ê³  ë¬¼ê±´ì´ ìì£¼ í’ˆì ˆëœë‹¤",
        "Student4": "ë„ì‹œë½ì´ ë§›ìˆê³  í• ì¸í–‰ì‚¬ê°€ ì¢‹ë‹¤",
        "Student5": "ì§ì›ì´ ì¹œì ˆí•˜ê³  ê³„ì‚°ì´ ë¹ ë¥´ë‹¤"
    },
    "ì˜í™”ë¦¬ë·°": {
        "Student1": "ìŠ¤í† ë¦¬ê°€ ê°ë™ì ì´ê³  ì¬ë¯¸ìˆë‹¤",
        "Student2": "ì „ê°œê°€ ëŠë¦¬ê³  ì§€ë£¨í–ˆë‹¤",
        "Student3": "ì•¡ì…˜ì´ ë§ê³  ê¸´ì¥ê°ì´ ì¢‹ì•˜ë‹¤",
        "Student4": "ì—°ê¸°ê°€ í›Œë¥­í•˜ê³  ëª°ì…ê°ì´ ìˆì—ˆë‹¤",
        "Student5": "ë‚´ìš©ì´ ë³µì¡í•˜ê³  ì´í•´í•˜ê¸° ì–´ë ¤ì› ë‹¤"
    }
}

# -----------------------------
# ìœ í‹¸ í•¨ìˆ˜ë“¤
# -----------------------------
def print_similarity_table(names, sim_matrix, title):
    print(f"\n[ìœ ì‚¬ë„ í–‰ë ¬] {title}")
    header = " " * 10 + " ".join([f"{n:>10}" for n in names])
    print(header)
    for i, n in enumerate(names):
        row = f"{n:>10} " + " ".join([f"{sim_matrix[i][j]:10.3f}" for j in range(len(names))])
        print(row)

def most_similar_pair(names, sim_matrix):
    max_sim = -1
    best_pair = None
    for i in range(len(names)):
        for j in range(i+1, len(names)):
            if sim_matrix[i][j] > max_sim:
                max_sim = sim_matrix[i][j]
                best_pair = (names[i], names[j])
    return best_pair, max_sim

def kmeans_cluster_labels(X, names, k=2):
    # í‘œë³¸ì´ ë„ˆë¬´ ì ìœ¼ë©´ kë¥¼ ìë™ìœ¼ë¡œ ì¤„ì„
    k = max(2, min(k, len(names)))
    model = KMeans(n_clusters=k, random_state=0, n_init=10)
    labels = model.fit_predict(X)
    return labels, k

# -----------------------------
# âœ… ì£¼ì œë³„ë¡œ ë”°ë¡œ ë¶„ì„
# -----------------------------
for topic, reviews in topic_reviews.items():
    print("\n" + "="*70)
    print(f"ì£¼ì œ: {topic}")
    print("="*70)

    # 1) ë¦¬ë·° ì¶œë ¥
    print("\në¦¬ë·° ëª©ë¡:")
    for student, text in reviews.items():
        print(f"- {student}: {text}")

    # 2) Bag of Words ë²¡í„°í™”
    vectorizer = CountVectorizer()
    X = vectorizer.fit_transform(reviews.values())
    vocab = vectorizer.get_feature_names_out()

    print("\në‹¨ì–´ ì‚¬ì „(vocabulary) í¬ê¸°:", len(vocab))
    print("ë‹¨ì–´ ì‚¬ì „ ì¼ë¶€:", list(vocab)[:15], "..." if len(vocab) > 15 else "")

    # 3) ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
    sim = cosine_similarity(X)
    names = list(reviews.keys())

    # ìœ ì‚¬ë„ í–‰ë ¬ ì¶œë ¥
    print_similarity_table(names, sim, topic)

    # ê°€ì¥ ë¹„ìŠ·í•œ í•™ìƒ ìŒ
    pair, score = most_similar_pair(names, sim)
    print("\nâœ… ê°€ì¥ ì„±í–¥ì´ ë¹„ìŠ·í•œ í•™ìƒ ìŒ:")
    print(f"  {pair[0]} â†” {pair[1]}  (ì½”ì‚¬ì¸ ìœ ì‚¬ë„: {score:.3f})")

    # 4) (ì˜µì…˜) KMeans êµ°ì§‘í™”
    # ì£¼ì œë§ˆë‹¤ í•™ìƒë“¤ì„ kê°œ ê·¸ë£¹ìœ¼ë¡œ ë¬¶ì–´ "ì„±í–¥ì´ ë¹„ìŠ·í•œ í•™ìƒë¼ë¦¬ ê·¸ë£¹"ì„ ë§Œë“¤ê¸°
    labels, k_used = kmeans_cluster_labels(X, names, k=2)

    print(f"\nğŸ“Œ KMeans êµ°ì§‘í™” ê²°ê³¼ (k={k_used}):")
    clusters = {}
    for name, label in zip(names, labels):
        clusters.setdefault(label, []).append(name)

    for label, members in clusters.items():
        print(f"  - ê·¸ë£¹ {label}: {', '.join(members)}")

print("\n" + "="*70)
print("âœ… ì£¼ì œë³„ ë¶„ì„ ì™„ë£Œ")
print("="*70)
